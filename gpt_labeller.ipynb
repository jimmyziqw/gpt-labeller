{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4_openai import GPT4OpenAI\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Token is the __Secure-next-auth.session-token from chat.openai.com\n",
    "llm = GPT4OpenAI(token=\"eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0..eCl1OOqEnczrkfvG.DFv_rTqjEyOWXGrYJavVnY10rEMYGLrRmZd1oTX_ghPfv33yGVCS7QTIMnNX93Zxut6RBuomXIrxktITUqroW_7rNeT8X1L86Tdh4oy0fsqHM6J9O7UPfZkI74C7LA_XambtCkDftTmCUIvSkGpNEq7L9hjvHSwjGD5Yh1oCeieAfgCpPzewK25PaLhVCoafXCadwXBox8gR5ch4hd0SWw3HLqMhFdGByiTu-8dm_8IEBkJSSErU2wHKOe4lPURui3kghYGvyrFP8FLRWKaPUVpwubrnYaS3ZuhbJbar6TaUPnl600n7XjjyR5MoU8d6MjHunE3L_mLjZBYY0jiMG40Ki0q5s4HqvXdXVUj8Qqgbqa9yatciHgmvVJka6uEnINVQMsDoP_L4N6PU4nU6gGb2oZqYdD7iY1i62ob954bhAec7tUEw9BJMYC6SnmedVBhR-0DwbymDmAkRYpfDD4RXEclhcz8ptbhdcwa6-aVrM_uiLODXYIF8zAp8H52-QAJl6ZxYw7QoKEqd-N-dl7VLNwLNxvb_fyd_xs0fsTsYYVyldPuPDR6eyZFSe9rfqdAWrlXf3yISfefAbowfZcPcGhlnpr50CtESIyXhd_CwwjEeHkXFB4NXO5fS9tE6nGpKJagQT0VJUAH_VqmU2UQn-fRfxNemlCZXaeasa2bgZQPssxZXFq5IZfbST_Fi2WpQ74LRjOFCuELf5Pgg0qjQVkhIAv-sNNdlu0KfrQ-Sa5rW78EJLW_NnGEdOiqHOkE2Z3Ig8owLRu4WSIJOZTkDuHqAwhiqHaiLOaZvnZ-NwoTB1ENCq6rb1QEmoaE4RNCH9nZcCi8zAtkYj55OOcCfpgPLdxiDVzWu1iHJCCgSlUkiEUnQwZMgiwukK6yb4AD_qaP9l2BwCLFi0KAhmtXRi_-Hfm9OrvBCkCNt1j7_DHAP5G5GWg2XW9KuYjxKvi404hzmXmqUMPuLFRnOSGdk-nBwEk0LWO2gsgNk4qzBuPwhPYrs2Q2uwzhPjq4n9eR9DZOlmC024TDG49azXlZuB_6EUh4TyKjyS66GDvzvKXm4KxZZNwII3m1gbZodd5meJ-EiEzlWk-bgoMZJJkd-P96ur2FbSzwxr2O9FUZWDfT2-rOsNQemlqXZl_SHNZbLq1LX78-KS66aRcxmFpli35BM38lPUUPngL0K19bCFA28Izsxhk8vgm0RguWOHMMV5pdvGb6CsmwJFdHy3RIAIVz4jCLYHQPl_9ApKun5aXksKXU1uRhA_R_SCvioiDpDDz0vMNTRkM6TrM8zBxVuZr1Z-4iMZ0wdnMPs-MtQ0-GaaqvMA-xy2LL9EpRMzRhIQf-ZEWbpdKsYjJ8wMf1Q7NCQrKFeT8yXyFeOAVD4hZUEYVxEGafdu4zChzegRKLTO6se8GsBcH-l6WC6ydRnXVqr3Jyynz5MQ0f-JEveOdzBna2Fd9BRnUfDnWcgzlr-Y2bSxY0nsT8sLx_tUJ4PRxSh4sdqdIi1WXHyn0k-nMpTP6XaYNT6hovM1QRzzNOAis9A2Vj0l0Dyww3Wu2Uf7WPyg8kcl8K-fdCSvJSZxgoei8bJfGbh1ATtoGKzDL5Ay6sI-ePhjg5AtcsQdGJFP5djdP_1nsYYXo3hkKTWxjAjBAausrh2EgWx2PSLp5vtOQvNnHP_449w1nH2S5t5RynC3uBmBA3YWrOoW8fJkYCpWN0Zd9UupE36pQnHpbh_lljnyPU06RUzYpQhxHB0omXb68B--FVecY_67waNB4qDJ8OSaOguLlvzF9cPpHL3wACyCtv11d4QIudMUYGBZStxtBeAAlupH_lH5_o-amewQtqSwLrrR-aNtVfHvD5lVUuDyFrCARbgWezN21FoWbC8lsdykOZQxlrdolrYabzblfgfRc3yXrQefaC2uUdBCydalNG7t1QOHRHucFgM7WEiNUQ7rGFwX5N0IrDjgoDYMjLY_JCT6uEyBSkD64UG2cYWM_7olG20L9ut0GUAQlX9GaTlQPeWZIt0Szs8cPUL6eVVMHNi5BliS-G2MBD1r5s5L7zw6scfPCuOA2cceWGQbwo6k3_iRiQRX6lCodJ5nETXOYnN6R49K6S6d_nuEj3NuK9uEcJnYzY2cFCWZJiMA7xj-ubkbzMrYwxzfZaDHh4WEP8ClBdGtolDVQE6rricYZ5UtCq7ARpaoFBOiU8HDexEUF3Vqo3Pae5uyBPeawELFilGF5P1oIKQOkFJ3vxFp9I4KTtAKQqfpckOPRNqMBrtmDVg3lwy7h2X_ibs87aq-7CdL8cCF7WVEyTd3t76EhKiB8zoeiZ_WGQtcGZXPDmh8jpFXnDxdqL_htXMFAX1TSnBPMRrAUkP8vwkBOUNiIqwwDpPEFNssmmYei8RExhVsOAE8czqlhkGNebSVZgXwxsBZXhIj6MFjSMWatOEP8EWbaxo0XIyuUh6D-EIasEdsSM6ZEgDpGJ2ovtdG-zooARX55vdysaagFiLGu6NliQyJGqgl9foKx5sEDmsZgIAkdZBKV-T0107zvQi6310UIhm-Gq7SRqAWhL-QdkJXf37pVwytzCkq-YK3HbbzLiWgtKIEJkYThtTWodRY78kRPlmZt9o_WHrxY3DblFYIxd1qTZczW_t3nDdjkkUo94zy4D3sgy35E7lSkUkuuVwwxEynDcuUw.4GYwEvzensqkyDlEP3DnNw\", headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of reviews: 60; num of character: 3310;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 25; num of character: 2669;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 43; num of character: 2551;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 32; num of character: 3241;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 15; num of character: 1642;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 39; num of character: 3904;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 0; num of character: 332;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 46; num of character: 4064;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 5; num of character: 4042;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 21; num of character: 3923;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 26; num of character: 3947;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 10; num of character: 3401;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 13; num of character: 4081;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 57; num of character: 3813;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 25; num of character: 3734;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 60; num of character: 3955;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 33; num of character: 3925;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 27; num of character: 3703;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 47; num of character: 3547;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 11; num of character: 2846;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 10; num of character: 1187;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 36; num of character: 4084;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 21; num of character: 3709;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 38; num of character: 4003;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 48; num of character: 3710;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 60; num of character: 3865;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 25; num of character: 2894;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 25; num of character: 3445;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 30; num of character: 4021;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 41; num of character: 3839;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 34; num of character: 4048;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 13; num of character: 1916;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 10; num of character: 1956;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 36; num of character: 4063;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 7; num of character: 4076;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 9; num of character: 4078;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 17; num of character: 4036;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 37; num of character: 3832;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 13; num of character: 965;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 17; num of character: 3981;\n",
      ">>> WARNING <<<\n",
      ">> You don't have paid access to GPT4, using default model...\n",
      "num of reviews: 14; num of character: 4086;\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have reached the maximum number of requests per hour ! Help me to Improve. Abusing this tool is at your own risk",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m     request \u001b[39m=\u001b[39m  \u001b[39mstr\u001b[39m(reviews) \u001b[39m+\u001b[39minstruction \n\u001b[0;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum of reviews: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(reviews)\u001b[39m}\u001b[39;00m\u001b[39m; num of character: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(request)\u001b[39m}\u001b[39;00m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m response \u001b[39m=\u001b[39m llm(request)\n\u001b[0;32m     41\u001b[0m \u001b[39m#append new data\u001b[39;00m\n\u001b[0;32m     42\u001b[0m lines \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\AFUNFOLDER\\sparse-gpt\\venv\\lib\\site-packages\\langchain\\llms\\base.py:291\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[1;34m(self, prompt, stop, callbacks)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    287\u001b[0m     \u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check Cache and run the LLM on the given prompt and input.\"\"\"\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 291\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([prompt], stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m    292\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m    293\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[0;32m    294\u001b[0m     )\n",
      "File \u001b[1;32md:\\AFUNFOLDER\\sparse-gpt\\venv\\lib\\site-packages\\langchain\\llms\\base.py:191\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    192\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32md:\\AFUNFOLDER\\sparse-gpt\\venv\\lib\\site-packages\\langchain\\llms\\base.py:185\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[0;32m    180\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    181\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, invocation_params\u001b[39m=\u001b[39mparams\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 185\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    186\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    187\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32md:\\AFUNFOLDER\\sparse-gpt\\venv\\lib\\site-packages\\langchain\\llms\\base.py:407\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop, run_manager)\u001b[0m\n\u001b[0;32m    402\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    403\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m    404\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m    405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m    406\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m--> 407\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[0;32m    408\u001b[0m     )\n\u001b[0;32m    409\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[0;32m    410\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[1;32md:\\AFUNFOLDER\\sparse-gpt\\venv\\lib\\site-packages\\gpt4_openai\\__init__.py:42\u001b[0m, in \u001b[0;36mGPT4OpenAI._call\u001b[1;34m(self, prompt, stop)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m# OpenAI: 50 requests / hour for each account\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m45\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have reached the maximum number of requests per hour ! Help me to Improve. Abusing this tool is at your own risk\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     sleep(\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: You have reached the maximum number of requests per hour ! Help me to Improve. Abusing this tool is at your own risk"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\"Given the reviews above,\n",
    "Output at most 3 keywords from each review that brings insight to the topic. \n",
    "If there is no insightful keyword, output special character NULL. \n",
    "No generic description such as good, nice, best etc or digit output.\n",
    "Output result in format as 0:k1, k2 \\n 1:NULL \\n 2:k1, k2, k3 ...\n",
    "Only output english word. \n",
    "\"\"\"\n",
    "# dataset folders \n",
    "input_folder = os.path.join('dataset', 'steam_indie_500')\n",
    "output_folder = os.path.join('dataset', 'steam_indie_500_labelled')\n",
    "\n",
    "# select files that are not labelled\n",
    "input_file_list = os.listdir(input_folder)\n",
    "output_file_list = os.listdir(output_folder)\n",
    "file_list = list(set(input_file_list)-set(output_file_list))\n",
    "\n",
    "json_files = [file for file in file_list if file.endswith(\".json\")]\n",
    "json_files.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "\n",
    "\n",
    "# request gpt to label the keywords for each file\n",
    "for json_file in json_files[:50]:\n",
    "    \n",
    "    # load files\n",
    "    input_path = os.path.join(input_folder, json_file)\n",
    "    with open(input_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # write request\n",
    "    reviews = [(i,x[\"review\"]) for i, x in enumerate(data[:60])]\n",
    "    request =  str(reviews)+instruction\n",
    "    \n",
    "    while len(request)>=4096: #character cap to run the script smoothly\n",
    "        reviews = reviews[:-1]\n",
    "        request =  str(reviews) +instruction \n",
    "        \n",
    "    print(f\"num of reviews: {len(reviews)}; num of character: {len(request)};\")\n",
    "    response = llm(request)\n",
    "    \n",
    "    #append new data\n",
    "    lines = response.split('\\n')\n",
    "    new_data = []\n",
    "    for line, review in zip(lines, reviews):\n",
    "        if line != \"\":\n",
    "            idx, keyword = line.split(\":\")\n",
    "            new_data.append(dict(\n",
    "                review=review[-1],\n",
    "                keyword=keyword if keyword != \"NULL\" else None,\n",
    "            ))\n",
    "    new_data\n",
    "    output_path = os.path.join(output_folder, json_file)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(new_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:pain, divorce\\n1:NULL\\n2:настольгировать, игра, соболезную\\n3:worst, play, PvZ 1\\n4:classics, childhood, PvZ games\\n5:NULL\\n6:lane defence, holds up, today\\n7:NULL\\n8:best games, PC, post games\\n9:NULL\\n10:Fun, modders, first time\\n11:NULL\\n12:NULL\\n13:best classics, recommended, NULL\\n14:vegan, zombies, NULL\\n15:NULL\\n16:protect, home, plants\\n17:besturest, geam, NULL\\n18:NULL\\n19:oldie, basic computers, NULL\\n20:Plants Vs. Zombies, NULL\\n21:recommended, music, gameplay\\n22:childhood game, NULL\\n23:INVEST, ZEN GARDEN, NULL\\n24:amusing game, Popcap games, NULL\\n25:love, game, NULL\\n26:hours, good, game\\n27:NULL\\n28:born, game came out, NULL\\n29:melikeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, NULL\\n30:NULL\\n31:NULL\\n32:NULL\\n33:song, credits, NULL\\n34:fun, completed, game\\n35:NULL\\n36:mobile, pc, better versions\\n37:classic, fun, pvz series\\n38:NULL\\n39:nostalgic game, NULL\\n40:NULL\\n41:NULL\\n42:never disappoints, played for years, owned\\n43:best Tower defense, NULL\\n44:全成就纪念, 歪比歪比, 歪比八波\\n45:NULL\\n46:nostalgia, NULL\\n47:NULL\\n48:roses, violets, zombies\\n49:zombie, lawn, NULL\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# request gpt to label the keywords for each file\n",
    "for json_file in json_files[:50]:\n",
    "\n",
    "    # load files\n",
    "    input_path = os.path.join(input_folder, json_file)\n",
    "    with open(input_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # write request\n",
    "    reviews = [(i, x[\"review\"]) for i, x in enumerate(data[:60])]\n",
    "    request = str(reviews)+instruction\n",
    "\n",
    "    while len(request) >= 4096:  # character cap to run the script smoothly\n",
    "        reviews = reviews[:-1]\n",
    "        request = str(reviews) + instruction\n",
    "\n",
    "    print(f\"num of reviews: {len(reviews)}; num of character: {len(request)};\")\n",
    "    response = llm(request)\n",
    "\n",
    "    # append new data\n",
    "    lines = response.split('\\n')\n",
    "    new_data = []\n",
    "    for line, review in zip(lines, reviews):\n",
    "        if line != \"\":\n",
    "            idx, keyword = line.split(\":\")\n",
    "            new_data.append(dict(\n",
    "                review=review[-1],\n",
    "                keyword=keyword if keyword != \"NULL\" else None,\n",
    "            ))\n",
    "    new_data\n",
    "    output_path = os.path.join(output_folder, json_file)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(new_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:pain, divorce\n",
      "1:classic\n",
      "2:настольгировать, игра, соболезную\n",
      "3:worst, PvZ 1, mobile game market\n",
      "4:classics, childhood, PvZ games\n",
      "5:NULL\n",
      "6:lane defence, holds up, today\n",
      "7:zobie\n",
      "8:best games, PC, post games\n",
      "9:NULL\n",
      "10:modders, first time, Fun\n",
      "11:plamnt\n",
      "12:NULL\n",
      "13:best classics, recommended\n",
      "14:vegan, zombies\n",
      "15:NULL\n",
      "16:protect, home, Zombies, Plants\n",
      "17:besturest geam\n",
      "18:NULL\n",
      "19:oldie, basic computers\n",
      "20:Plants Vs. Zombies\n",
      "21:recommended, music, gameplay\n",
      "22:childhood game\n",
      "23:INVEST, ZEN GARDEN\n",
      "24:amusing game, Popcap games\n",
      "25:love, game\n",
      "26:hours, good\n",
      "27:NULL\n",
      "28:born, game came out\n",
      "29:NULL\n",
      "30:NULL\n",
      "31:NULL\n",
      "32:NULL\n",
      "33:song, credits\n",
      "34:fun, completed\n",
      "35:NULL\n",
      "36:mobile, pc, versions\n",
      "37:classic, introduced, pvz series\n",
      "38:NULL\n",
      "39:nostalgic game\n",
      "40:NULL\n",
      "41:NULL\n",
      "42:never disappoints, console, PC\n",
      "43:best Tower defense\n",
      "44:NULL\n",
      "45:NULL\n",
      "46:nostalgia\n",
      "47:NULL\n",
      "48:roses, violets, cool, plants\n",
      "49:zombie, lawn\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m j\u001b[39m.\u001b[39;49mkeys()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
